{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIyI6WGqRed5"
   },
   "source": [
    "# TensorFlow model converter\n",
    "This notebook is meant to convert TensorFlow Sequential models to:\n",
    "- Tensorflow Lite   (Fully supported)\n",
    "- Torch             (Not supported, hardcoded conversion function for each layer type)\n",
    "- ONNX              (Not supported, exported from Torch model)\n",
    "- RTNeural weights  ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s5lqGuYlQaVE"
   },
   "outputs": [],
   "source": [
    "# Specify TensorFlow version required for compatibility. Set the variable at None if not relevant\n",
    "TENSORFLOW_VERSION_REQUIRED = '2.4.1'\n",
    "# TENSORFLOW_VERSION_REQUIRED = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b-yFF2h1QKRv"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "if tf.version.VERSION != TENSORFLOW_VERSION_REQUIRED:\n",
    "    !pip uninstall tensorflow -y\n",
    "    !pip install tensorflow==2.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LYGbdW6GRbdX",
    "outputId": "2d2c51f1-c7ce-4603-e330-94b07c003996"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "from json import JSONEncoder\n",
    "import torch\n",
    "import os\n",
    "\n",
    "if TENSORFLOW_VERSION_REQUIRED and tf.version.VERSION != TENSORFLOW_VERSION_REQUIRED:\n",
    "    raise Exception('Error! Tensorflow version ('+tf.version.VERSION+') is different from the required version ('+TENSORFLOW_VERSION_REQUIRED+'). Run the previous cell and restart runtime if running on Colab.')\n",
    "else:\n",
    "    print(\"Imported TensorFlow \"+tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ubCPneMNPfDQ"
   },
   "outputs": [],
   "source": [
    "# Settings\n",
    "TF_MODEL_PATH = \"./TF_ModelA\"     # Path to input TensorFlow Model\n",
    "OUT_MODEL_NAME = 'ModelA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y-827vqKPfDW"
   },
   "outputs": [],
   "source": [
    "TF_MODEL_PATH = os.path.abspath(TF_MODEL_PATH)              # Remove potential trailing separator from path\n",
    "SAVE_MODEL_PATH = OUT_MODEL_NAME+\"-converted\"   # Directory where to save output models\n",
    "!mkdir -p \"$SAVE_MODEL_PATH\"                                # Create dir\n",
    "\n",
    "# Load tensorflow model\n",
    "tfmodel = tf.keras.models.load_model(TF_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JiZmDsuXjoM8"
   },
   "source": [
    "## TF Lite Conversion\n",
    "This is directly supported by TensorFlow.\n",
    "\n",
    "Remember to set the TensorFlow version at the beginning of this notebook according to the version of the Interpreter that will run on the target system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gbcepDgUjdnq"
   },
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(TF_MODEL_PATH)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with tf.io.gfile.GFile(SAVE_MODEL_PATH + '/tflite_'+OUT_MODEL_NAME+'_.tflite', 'wb') as f:\n",
    "        f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "esrpKEX_ew94"
   },
   "source": [
    "## Torch Conversion\n",
    "TF to Torch model conversion is not supported at the moment.\n",
    "This was coded for the special case of Dense/Linear sequential models with batchNorm Layers and **it will not work with other layer types**.\n",
    "\n",
    "The code below can inspire the addition of more conversion functions (i.e. for different layer types).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pchYX9vnfEDk"
   },
   "outputs": [],
   "source": [
    "class TF2Torch(torch.nn.Module):\n",
    "\n",
    "    def dense2linear(self, dense : tf.keras.layers.Dense):\n",
    "        # Retrieve dimensions\n",
    "        in_features, out_features = dense.kernel.shape\n",
    "        # Initialize fully connected (Linear) layer with given dimensions\n",
    "        out = torch.nn.Linear(in_features, out_features)\n",
    "        # Copy parameters\n",
    "        out.weight.data = torch.Tensor(dense.kernel.numpy().transpose()) # Transposed weights due to different standards\n",
    "        out.bias.data = torch.Tensor(dense.bias.numpy().transpose())     # Transposed weights due to different standards\n",
    "        return out\n",
    "\n",
    "    def batchNormalization2BatchNorm1d(self, batch_normalization : tf.keras.layers.BatchNormalization):\n",
    "        # Retrieve dimensions\n",
    "        num_features = batch_normalization.gamma.shape[0]\n",
    "        # Initialize fully connected (Linear) layer with given dimensions\n",
    "        out : torch.nn.BatchNorm1d = torch.nn.BatchNorm1d(num_features)\n",
    "        # Copy parameters\n",
    "        out.weight.data = torch.Tensor(batch_normalization.gamma.numpy())\n",
    "        out.bias.data = torch.Tensor(batch_normalization.beta.numpy())\n",
    "        out.running_mean = torch.Tensor(batch_normalization.moving_mean.numpy())\n",
    "        out.running_var = torch.Tensor(batch_normalization.moving_variance.numpy())\n",
    "        out.momentum = batch_normalization.momentum\n",
    "        out.eps = batch_normalization.epsilon\n",
    "        return out\n",
    "\n",
    "    def __init__(self, tfmodel):\n",
    "        super(TF2Torch, self).__init__()\n",
    "\n",
    "        def populate(tflayers):\n",
    "            for l in tflayers:\n",
    "                if type(l) is tf.keras.layers.BatchNormalization:\n",
    "                    yield self.batchNormalization2BatchNorm1d(l)\n",
    "                elif type(l) is tf.keras.layers.Dense:\n",
    "                    yield self.dense2linear(l)\n",
    "                    if l.activation is tf.keras.activations.linear:\n",
    "                        continue\n",
    "                    elif l.activation is tf.keras.activations.relu:\n",
    "                        yield torch.nn.ReLU()\n",
    "                    else:\n",
    "                        raise NotImplementedError(\"Conversion for activation function {} not implemented.\".format(l.activation))\n",
    "                    \n",
    "                elif type(l) is tf.keras.layers.Dropout:\n",
    "                    yield torch.nn.Dropout(l.rate)\n",
    "                else:\n",
    "                    raise NotImplementedError(\"Conversion for layer type {} not implemented.\".format(type(l)))\n",
    "        \n",
    "        self.model = torch.nn.Sequential(*list(populate(tfmodel.layers)))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XTnuHPN5PfDY"
   },
   "outputs": [],
   "source": [
    "# Convert to PyTorch model, export TorchScript model by scripting\n",
    "torchmodel = TF2Torch(tfmodel)\n",
    "\n",
    "scripted_model = torch.jit.script(torchmodel)\n",
    "scripted_model.save(SAVE_MODEL_PATH + \"/torchscript_\"+OUT_MODEL_NAME+\"_.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ouGt1u6e9EW"
   },
   "source": [
    "## ONNX Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y3bMddmePfDZ"
   },
   "outputs": [],
   "source": [
    "# Export onnx model by tracing (see https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html)\n",
    "import torch.onnx\n",
    "\n",
    "INPUT_SIZE = tfmodel.layers[0].get_input_at(0).get_shape().as_list()[1]\n",
    "x = torch.ones(INPUT_SIZE).unsqueeze(0) # dummy input for tracing\n",
    "\n",
    "torch.onnx.export(torchmodel,                                       # Model\n",
    "                  x,                                                # Input\n",
    "                  SAVE_MODEL_PATH + \"/onnx_\"+OUT_MODEL_NAME+\".onnx\",  # Output file\n",
    "                  export_params=True,                               # Export trained parameters\n",
    "                  do_constant_folding=True,                         # Perform constant folding\n",
    "                  input_names = ['input'],                          # Label for input\n",
    "                  output_names = ['output']                         # Label for output\n",
    "                  ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YaH6f14serap"
   },
   "source": [
    "## RT Neural Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jltbyOoTeCWQ"
   },
   "outputs": [],
   "source": [
    "class NumpyArrayEncoder(JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return JSONEncoder.default(self, obj)\n",
    "\n",
    "class Tf2RtneuralConverter:\n",
    "    def save_model_json(self,model):\n",
    "        def get_layer_type(layer):\n",
    "            if isinstance(layer, tf.keras.layers.TimeDistributed):\n",
    "                return 'time-distributed-dense'\n",
    "\n",
    "            if isinstance(layer, tf.keras.layers.GRU):\n",
    "                return 'gru'\n",
    "\n",
    "            if isinstance(layer, tf.keras.layers.LSTM):\n",
    "                return 'lstm'\n",
    "\n",
    "            if isinstance(layer, tf.keras.layers.Dense):\n",
    "                return 'dense'\n",
    "\n",
    "            if isinstance(layer, tf.keras.layers.Conv1D):\n",
    "                return 'conv1d'\n",
    "\n",
    "            return 'unknown'\n",
    "\n",
    "        def get_layer_activation(layer):\n",
    "            if isinstance(layer, tf.keras.layers.TimeDistributed):\n",
    "                return get_layer_activation(layer.layer)\n",
    "\n",
    "            if layer.activation == tf.keras.activations.tanh:\n",
    "                return 'tanh'\n",
    "\n",
    "            if layer.activation == tf.keras.activations.relu:\n",
    "                return 'relu'\n",
    "\n",
    "            if layer.activation == tf.keras.activations.sigmoid:\n",
    "                return 'sigmoid'\n",
    "\n",
    "            if layer.activation == tf.keras.activations.softmax:\n",
    "                return 'softmax'\n",
    "            \n",
    "            return ''\n",
    "\n",
    "        def save_layer(layer):\n",
    "            layer_type = get_layer_type(layer)\n",
    "            if layer_type == 'unknown':\n",
    "                return None\n",
    "            layer_dict = {\n",
    "                \"type\"       : layer_type,\n",
    "                \"activation\" : get_layer_activation(layer),\n",
    "                \"shape\"      : layer.output_shape,\n",
    "                \"weights\"    : layer.get_weights()\n",
    "            }\n",
    "\n",
    "            if layer_dict[\"type\"] == \"conv1d\":\n",
    "                layer_dict[\"kernel_size\"] = layer.kernel_size\n",
    "                layer_dict[\"dilation\"] = layer.dilation_rate\n",
    "\n",
    "            return layer_dict\n",
    "\n",
    "\n",
    "        model_dict = {}\n",
    "        model_dict[\"in_shape\"] = model.input_shape\n",
    "        layers = []\n",
    "        for layer in model.layers:\n",
    "            layer_dict = save_layer(layer)\n",
    "            if layer_dict is not None:\n",
    "                layers.append(layer_dict)\n",
    "\n",
    "        model_dict[\"layers\"] = layers\n",
    "        return model_dict\n",
    "\n",
    "    def save_model(self, model, filename):\n",
    "        model_dict = self.save_model_json(model)\n",
    "        with open(filename, 'w') as outfile:\n",
    "            json.dump(model_dict, outfile, cls=NumpyArrayEncoder, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BOcdYPtZPfDa"
   },
   "outputs": [],
   "source": [
    "# Export RTNeural model (json weights)\n",
    "\n",
    "rtneuralconverter = Tf2RtneuralConverter()\n",
    "rtneuralconverter.save_model(tfmodel, SAVE_MODEL_PATH + \"/rtneural_\"+OUT_MODEL_NAME+\"_.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UnTMQQ94l1s7"
   },
   "source": [
    "## Compress models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hZyid93dl0Dq",
    "outputId": "1e2e3ef9-719a-4a25-a6ef-c2f6c7288e5b"
   },
   "outputs": [],
   "source": [
    "archivename = 'convertedmodels_' +OUT_MODEL_NAME + '.tar.gz'\n",
    "outdirname = os.path.dirname(SAVE_MODEL_PATH)\n",
    "outlastdname = os.path.basename(SAVE_MODEL_PATH)\n",
    "\n",
    "if outdirname != \"\":\n",
    "    !cd \"$outdirname\" ; tar -czvf \"$archivename\" \"$outlastdname\"\n",
    "else:\n",
    "    !tar -czvf \"$archivename\" \"$outlastdname\"\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of tf_converter.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "37b255bb5dc0d995b91bd1b934b878e610a26475f52eafaf29fdb395fb105534"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
